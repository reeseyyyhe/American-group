{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Matching Algorithm with a toy example\n",
    "\n",
    "* We will display one possible approach to match records using the existing rltk algorithm and Gale Shapley matching algorithm in this file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds1 = pd.read_csv('C:/Columbia_University/Research/History_African_American_Migration_Pattern/US_MLP_datasets/1880 from 1880-1900 experiment.csv')\n",
    "ds2 = pd.read_csv('C:/Columbia_University/Research/History_African_American_Migration_Pattern/US_MLP_datasets/1900 from 1880-1900 experiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1[\"matching_id\"] = None\n",
    "ds2[\"matching_id\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(dataset1, dataset2):\n",
    "\n",
    "    df = {index1: [] for index1, row1 in dataset1.iterrows()}\n",
    "    \n",
    "\n",
    "    for index1, row1 in dataset1.iterrows():\n",
    "        score_list = []\n",
    "        \n",
    "        \n",
    "        histid1 = row1['histid']\n",
    "        firstname1 = row1['namefrst']\n",
    "        lastname1 = row1['namelast']\n",
    "        birthplace1 = row1['bpl']\n",
    "\n",
    "        for index2, row2 in dataset2.iterrows():\n",
    "\n",
    "            histid2 = row2['histid']\n",
    "            firstname2 = row2['namefrst']\n",
    "            lastname2 = row2['namelast']\n",
    "            birthplace2 = row2['bpl']  \n",
    "\n",
    "            histid_score =  rltk.levenshtein_similarity(histid1, histid2)*0.4\n",
    "            firstname_score = rltk.levenshtein_similarity(firstname1, firstname2)*0.2\n",
    "            lastname_score = rltk.levenshtein_similarity(lastname1, lastname2)*0.2\n",
    "\n",
    "            if birthplace1 == birthplace2:\n",
    "                birthplace_score = 1*0.2\n",
    "            else:\n",
    "                birthplace_score = 0*0.2\n",
    "\n",
    "            total_score = histid_score + firstname_score + lastname_score + birthplace_score\n",
    "            \n",
    "            score_list.append(total_score)\n",
    "\n",
    "        df[index1].extend(score_list)\n",
    "\n",
    "    return pd.DataFrame(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the rltk algorithm to help us create a matrix showing a linkage score between any pair of records in two datasets. Higher the score, the more likely the two records become a match. For example, the record 0 in dataset1 and the record 1 from dataset2 has a score of 0.168889."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.117460</td>\n",
       "      <td>0.168889</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.197778</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.184444</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.158333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  0.117460  0.168889  0.095238  0.055556  0.125000\n",
       "1  0.077778  0.066667  0.197778  0.077778  0.111111\n",
       "2  0.184444  0.120000  0.188889  0.077778  0.158333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = create_dataframe(ds1, ds2)\n",
    "create_dataframe(ds1, ds2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then include Gale Shapley algorithm below, and this algorithm returns a list of matching pairs based on the best scores. Each pair consists of one record from one dataset and one record from another dataset. Some records might not find a matching, so its matching record is None in that pair. We will also attach the associated score given each successful match in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gale_shapley(score_df):\n",
    "    # Get the list of row and column names\n",
    "    proposing_set = score_df.index.tolist()\n",
    "    receiving_set = score_df.columns.tolist()\n",
    "    \n",
    "    # Initialize dictionaries to store engagements\n",
    "    engagements = {}\n",
    "    reverse_engagements = {}\n",
    "\n",
    "    # Initialize all elements as free\n",
    "    free_proposers = proposing_set[:]\n",
    "    for receiver in receiving_set:\n",
    "        engagements[receiver] = None\n",
    "\n",
    "    while free_proposers:\n",
    "        proposer = free_proposers.pop(0) # get the list element at the a specific position\n",
    "        # and reduce list without that element in place (this is just one row in dataset A)\n",
    "        proposals = score_df.loc[proposer].sort_values(ascending=False).index.tolist()\n",
    "        # we find the best match of this row from dataset A in dataset B and we will finalize it in the following...\n",
    "\n",
    "        for receiver in proposals:\n",
    "            if receiver not in reverse_engagements.values():\n",
    "                engagements[receiver] = proposer\n",
    "                reverse_engagements[proposer] = receiver\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                current_proposer = engagements[receiver] \n",
    "                if score_df.loc[proposer, receiver] > score_df.loc[current_proposer, receiver]:\n",
    "                    engagements[receiver] = proposer\n",
    "                    reverse_engagements[proposer] = receiver\n",
    "                    free_proposers.append(current_proposer)\n",
    "                    break\n",
    "    \n",
    "\n",
    "    matches = [(proposer, receiver) for receiver, proposer in engagements.items()]\n",
    "    matches_with_scores = []\n",
    "    for pair in matches:\n",
    "        if pair[0] is not None and pair[1] is not None:\n",
    "            matches_with_scores.append((pair[0], pair[1], score_df.iloc[pair[0], pair[1]]))\n",
    "        else:\n",
    "            matches_with_scores.append(pair)\n",
    "    \n",
    "    return matches_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0, 0.18444444444444447),\n",
       " (0, 1, 0.16888888888888887),\n",
       " (1, 2, 0.19777777777777777),\n",
       " (None, 3),\n",
       " (None, 4)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = gale_shapley(score_df)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function below will help us get rid of pairs whose records fail to find a matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pairs(matches_with_scores):\n",
    "    return [pair for pair in matches_with_scores if len(pair) == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0, 0.18444444444444447),\n",
       " (0, 1, 0.16888888888888887),\n",
       " (1, 2, 0.19777777777777777)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_matchings = clean_pairs(matches)\n",
    "clean_matchings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lastly, we establish thresholds to classify each successful match as a Yes(meaning it is almost certain that the two records are a match), Maybe(the two records could be a match), or No (the two records are most likely not a match) match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_matches(matching_pairs_with_scores):\n",
    "    # Sort the list of tuples based on the score from highest to lowest\n",
    "    sorted_matches = sorted(matching_pairs_with_scores, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # Determine the number of elements in each label category\n",
    "    total_pairs = len(sorted_matches)\n",
    "    yes_threshold = int(0.1 * total_pairs)\n",
    "    maybe_threshold = int(0.5 * total_pairs)\n",
    "    \n",
    "    # Initialize lists to store the labeled matches (Yes, Maybe, or No match)\n",
    "    yes_matches = sorted_matches[:yes_threshold]\n",
    "    maybe_matches = sorted_matches[yes_threshold:maybe_threshold]\n",
    "    no_matches = sorted_matches[maybe_threshold:]\n",
    "    \n",
    "    return yes_matches, maybe_matches, no_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [(1, 2, 0.19777777777777777)],\n",
       " [(2, 0, 0.18444444444444447), (0, 1, 0.16888888888888887)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_matches(clean_matchings) # so, in this toy example, we have 0 Yes match, 1 Maybe match, and 2 No matches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: the threshold to classify and label matches as well as the criteria to compute the linkage score before can be changed flexibly based on need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
